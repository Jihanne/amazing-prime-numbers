Problem 1:
worst case scenario euclid's algorithm achieved when two consecutive fibonacci numbers are the inputs (x, y)
the table is a plot of all consecutive fibonacci numbers (up to the 300th), and iterations increase by 1 every time

Problem 3:
sieve algorithm is incredibly inefficient unless one sieve containing primes is produced and the list is searched for multiple inputs.
note that the worst case scenario for this approach is when the number is either composite (not in the list), or is the last
prime. still, it takes incredibly little time to search the sieve for the prime number but a lot of time to produce the initial sieve.

trial division is surprisingly efficient for numbers for up to 5 digits
note that the worst case scenario for this approach is when the number is the largest prime (for the number of digits)

fermat's efficiency depends largely on the random integer produced as this has the potential to produce a large integer to perform the modulo function. note that the worst case scenario for this approach is when the number is prime and large (and the generated random integer is also large)

as such, the tested inputs are the largest primes of digits 1 through 5.

increasing the number of digits proves to overwhelm sieve and fermat.

Problem 5:
direct correlation between number and number of primes below said number (from graph)
